import tensorrt as trt
import pycuda.driver as cuda
import pycuda.autoinit  # è‡ªåŠ¨åˆå§‹åŒ–CUDAä¸Šä¸‹æ–‡
import os
import time
import argparse
import numpy as np
import cv2  # ä½¿ç”¨OpenCVæ›¿ä»£PIL
import glob

class Int8Calibrator(trt.IInt8EntropyCalibrator2):
    """INT8æ ¡å‡†å™¨"""
    def __init__(self, calibration_images, cache_file, batch_size=1, max_calibration_samples=100):
        trt.IInt8EntropyCalibrator2.__init__(self)
        self.cache_file = cache_file
        self.batch_size = batch_size
        self.current_index = 0
        self.max_calibration_samples = max_calibration_samples
        
        # ç¡®ä¿CUDAä¸Šä¸‹æ–‡
        cuda.init()
        self.device = cuda.Device(0)
        self.context = self.device.make_context()
        
        # é¢„å¤„ç†æ ¡å‡†å›¾åƒ
        self.calibration_data = self.load_calibration_data(calibration_images)
        self.device_input = None
        
        print(f"ğŸ“Š INT8æ ¡å‡†å™¨åˆå§‹åŒ–å®Œæˆï¼Œæ ¡å‡†å›¾åƒæ•°é‡: {len(self.calibration_data)}")
    
    def __del__(self):
        """æ¸…ç†CUDAä¸Šä¸‹æ–‡"""
        try:
            if hasattr(self, 'device_input') and self.device_input:
                self.device_input.free()
            if hasattr(self, 'context'):
                self.context.pop()
        except:
            pass
    
    def load_calibration_data(self, calibration_images):
        """åŠ è½½å¹¶é¢„å¤„ç†æ ¡å‡†æ•°æ® - ä½¿ç”¨cv2çº¿æ€§resizeï¼Œæ— ImageNetå½’ä¸€åŒ–"""
        calibration_data = []
        print("ğŸ“‚ åŠ è½½æ ¡å‡†æ•°æ®...")
        
        for img_path in calibration_images[:self.max_calibration_samples]:  # ä½¿ç”¨å‚æ•°æ§åˆ¶æ•°é‡
            try:
                # ä½¿ç”¨cv2è¯»å–å›¾åƒ
                image = cv2.imread(img_path)
                if image is None:
                    print(f"è·³è¿‡æ— æ•ˆå›¾åƒ {img_path}: æ— æ³•è¯»å–")
                    continue
                
                # BGRè½¬RGB
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                
                # ä½¿ç”¨cv2çº¿æ€§resizeåˆ°ç›®æ ‡å°ºå¯¸
                image = cv2.resize(image, (320, 256), interpolation=cv2.INTER_LINEAR)
                
                # è½¬æ¢ä¸ºfloat32å¹¶å½’ä¸€åŒ–åˆ°[0,1]
                image = image.astype(np.float32) / 255.0
                
                # è½¬æ¢ä¸ºCHWæ ¼å¼ (Channel, Height, Width)
                image = np.transpose(image, (2, 0, 1))
                
                calibration_data.append(image)
                
            except Exception as e:
                print(f"è·³è¿‡æ— æ•ˆå›¾åƒ {img_path}: {e}")
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(calibration_data)} å¼ æ ¡å‡†å›¾åƒ")
        return calibration_data
    
    def get_batch_size(self):
        return self.batch_size
    
    def get_batch(self, names):
        """è·å–ä¸‹ä¸€æ‰¹æ ¡å‡†æ•°æ®"""
        try:
            if self.current_index + self.batch_size > len(self.calibration_data):
                return None
            
            # ç¡®ä¿CUDAä¸Šä¸‹æ–‡å¤„äºæ´»åŠ¨çŠ¶æ€
            self.context.push()
            
            # å‡†å¤‡æ‰¹æ¬¡æ•°æ®
            batch = []
            for i in range(self.batch_size):
                batch.append(self.calibration_data[self.current_index + i])
            
            batch = np.stack(batch, axis=0).astype(np.float32)
            self.current_index += self.batch_size
            
            # åˆ†é…GPUå†…å­˜ï¼ˆå¦‚æœè¿˜æ²¡æœ‰åˆ†é…ï¼‰
            if self.device_input is None:
                self.device_input = cuda.mem_alloc(batch.nbytes)
            
            # å¤åˆ¶æ•°æ®åˆ°GPU
            cuda.memcpy_htod(self.device_input, batch)
            
            print(f"ğŸ”„ æ ¡å‡†è¿›åº¦: {self.current_index}/{len(self.calibration_data)}")
            
            # ä¿æŒä¸Šä¸‹æ–‡æ´»åŠ¨çŠ¶æ€ï¼Œä¸è¦pop
            return [self.device_input]
            
        except Exception as e:
            print(f"âŒ æ ¡å‡†æ‰¹æ¬¡è·å–å¤±è´¥: {e}")
            try:
                self.context.pop()
            except:
                pass
            return None
    
    def read_calibration_cache(self):
        """è¯»å–æ ¡å‡†ç¼“å­˜"""
        if os.path.exists(self.cache_file):
            with open(self.cache_file, "rb") as f:
                print(f"ğŸ“ è¯»å–æ ¡å‡†ç¼“å­˜: {self.cache_file}")
                return f.read()
        return None
    
    def write_calibration_cache(self, cache):
        """å†™å…¥æ ¡å‡†ç¼“å­˜"""
        with open(self.cache_file, "wb") as f:
            f.write(cache)
        print(f"ğŸ’¾ ä¿å­˜æ ¡å‡†ç¼“å­˜: {self.cache_file}")

class ONNXToTensorRTConverter:
    def __init__(self, logger_level=trt.Logger.WARNING):
        """åˆå§‹åŒ–ONNXåˆ°TensorRTè½¬æ¢å™¨"""
        self.logger = trt.Logger(logger_level)
        print("ğŸ”§ åˆå§‹åŒ–TensorRTè½¬æ¢å™¨...")
        
        # åˆå§‹åŒ–CUDA
        try:
            cuda.init()
            print("âœ… CUDAåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸  CUDAåˆå§‹åŒ–è­¦å‘Š: {e}")
            print("ç»§ç»­ä½¿ç”¨é»˜è®¤CUDAä¸Šä¸‹æ–‡...")
    
    def find_calibration_images(self, calibration_dir):
        """æŸ¥æ‰¾æ ¡å‡†å›¾åƒ"""
        if not calibration_dir or not os.path.exists(calibration_dir):
            raise ValueError(f"æ ¡å‡†æ•°æ®ç›®å½•ä¸å­˜åœ¨: {calibration_dir}")
        
        # æ”¯æŒå¤šç§å›¾åƒæ ¼å¼
        extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']
        calibration_images = []
        
        for ext in extensions:
            calibration_images.extend(glob.glob(os.path.join(calibration_dir, ext)))
            calibration_images.extend(glob.glob(os.path.join(calibration_dir, ext.upper())))
        
        if len(calibration_images) == 0:
            raise ValueError(f"åœ¨ {calibration_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°æ ¡å‡†å›¾åƒ")
        
        print(f"ğŸ“ æ‰¾åˆ° {len(calibration_images)} å¼ æ ¡å‡†å›¾åƒ")
        return sorted(calibration_images)
    
    def set_layer_precision_constraints(self, network, precision):
        """è®¾ç½®å±‚çº§ç²¾åº¦çº¦æŸä»¥ä¿æŒæ¨¡å‹ç²¾åº¦"""
        if precision == 'fp16':
            # å¯¹äºæŸäº›å…³é”®å±‚ä¿æŒFP32ç²¾åº¦
            critical_layer_types = [
                trt.LayerType.SOFTMAX,
                trt.LayerType.REDUCE,
                trt.LayerType.TOPK
            ]
            
            for i in range(network.num_layers):
                layer = network.get_layer(i)
                if layer.type in critical_layer_types:
                    layer.precision = trt.float32
                    layer.set_output_type(0, trt.float32)
                    print(f"ğŸ”§ è®¾ç½®å…³é”®å±‚ {layer.name} ä¸ºFP32ç²¾åº¦")
        
        elif precision == 'int8':
            # å¯¹äºINT8ï¼ŒæŸäº›å±‚ä¿æŒFP16æˆ–FP32
            sensitive_layer_types = [
                trt.LayerType.SOFTMAX,
                trt.LayerType.REDUCE,
                trt.LayerType.TOPK,
                trt.LayerType.NORMALIZATION
            ]
            
            for i in range(network.num_layers):
                layer = network.get_layer(i)
                if layer.type in sensitive_layer_types:
                    layer.precision = trt.float16
                    layer.set_output_type(0, trt.float16)
                    print(f"ğŸ”§ è®¾ç½®æ•æ„Ÿå±‚ {layer.name} ä¸ºFP16ç²¾åº¦")
        
        print(f"âœ… å±‚çº§ç²¾åº¦çº¦æŸè®¾ç½®å®Œæˆ")
    
    def convert(self, onnx_path, output_path=None, precision='fp16', max_batch_size=8, 
                workspace_size=4, calibration_dir=None, calibration_samples=100, 
                enable_strict_types=True, enable_tactic_sources=True):
        """
        å°†ONNXæ¨¡å‹è½¬æ¢ä¸ºTensorRTå¼•æ“ - ä¼˜åŒ–ç‰ˆæœ¬
        
        Args:
            onnx_path: ONNXæ¨¡å‹è·¯å¾„
            output_path: è¾“å‡ºTensorRTå¼•æ“è·¯å¾„
            precision: ç²¾åº¦æ¨¡å¼ ('fp32', 'fp16', 'int8')
            max_batch_size: æœ€å¤§æ‰¹æ¬¡å¤§å°
            workspace_size: å·¥ä½œç©ºé—´å¤§å° (GB)
            calibration_dir: INT8æ ¡å‡†æ•°æ®ç›®å½•
            calibration_samples: æ ¡å‡†æ ·æœ¬æ•°é‡
            enable_strict_types: å¯ç”¨ä¸¥æ ¼ç±»å‹æ£€æŸ¥
            enable_tactic_sources: å¯ç”¨æ‰€æœ‰ç­–ç•¥æº
        """
        # è®¾ç½®è¾“å‡ºè·¯å¾„
        if output_path is None:
            output_path = onnx_path.replace('.onnx', f'_tensorrt_{precision}.trt')
        
        print(f"ğŸ”„ å¼€å§‹ONNXåˆ°TensorRTè½¬æ¢...")
        print(f"è¾“å…¥ONNX: {onnx_path}")
        print(f"è¾“å‡ºå¼•æ“: {output_path}")
        print(f"ç²¾åº¦æ¨¡å¼: {precision}")
        print(f"æœ€å¤§æ‰¹æ¬¡: {max_batch_size}")
        print(f"å·¥ä½œç©ºé—´: {workspace_size} GB")
        
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
        if not os.path.exists(onnx_path):
            raise FileNotFoundError(f"ONNXæ–‡ä»¶ä¸å­˜åœ¨: {onnx_path}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # åˆ›å»ºbuilderå’Œnetwork
        builder = trt.Builder(self.logger)
        config = builder.create_builder_config()
        
        # è®¾ç½®å·¥ä½œç©ºé—´
        config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, workspace_size * (1 << 30))
        
        # å¯ç”¨é«˜çº§ä¼˜åŒ–é€‰é¡¹
        if enable_strict_types:
            config.set_flag(trt.BuilderFlag.STRICT_TYPES)
            print("ğŸ”§ å¯ç”¨ä¸¥æ ¼ç±»å‹æ£€æŸ¥")
        
        # å¯ç”¨æ‰€æœ‰ç­–ç•¥æºä»¥è·å¾—æœ€ä½³æ€§èƒ½
        if enable_tactic_sources:
            config.set_flag(trt.BuilderFlag.PREFER_PRECISION_CONSTRAINTS)
            print("ğŸ”§ å¯ç”¨ç²¾åº¦çº¦æŸä¼˜åŒ–")
        
        # å¯ç”¨GPUå›é€€
        config.set_flag(trt.BuilderFlag.GPU_FALLBACK)
        print("ğŸ”§ å¯ç”¨GPUå›é€€")
        
        # è®¾ç½®ç²¾åº¦
        if precision == 'fp16':
            config.set_flag(trt.BuilderFlag.FP16)
            # å¯¹äºFP16ï¼Œä¹Ÿå¯ç”¨FP32å›é€€ä»¥ä¿è¯ç²¾åº¦
            config.set_flag(trt.BuilderFlag.OBEY_PRECISION_CONSTRAINTS)
            print("ğŸ¯ å¯ç”¨FP16ç²¾åº¦ä¼˜åŒ–ï¼ˆå¸¦FP32å›é€€ï¼‰")
        elif precision == 'int8':
            config.set_flag(trt.BuilderFlag.INT8)
            config.set_flag(trt.BuilderFlag.FP16)  # INT8é€šå¸¸éœ€è¦FP16æ”¯æŒ
            config.set_flag(trt.BuilderFlag.OBEY_PRECISION_CONSTRAINTS)
            print("ğŸ¯ å¯ç”¨INT8ç²¾åº¦ä¼˜åŒ–ï¼ˆå¸¦FP16æ”¯æŒï¼‰")
            
            # INT8éœ€è¦æ ¡å‡†æ•°æ®
            if calibration_dir is None:
                raise ValueError("INT8é‡åŒ–éœ€è¦æä¾›æ ¡å‡†æ•°æ®ç›®å½• --calibration-dir")
            
            # å‡†å¤‡æ ¡å‡†å™¨
            calibration_images = self.find_calibration_images(calibration_dir)
            cache_file = output_path.replace('.trt', '_calibration.cache')
            calibrator = Int8Calibrator(calibration_images, cache_file, batch_size=1, 
                                      max_calibration_samples=calibration_samples)
            config.int8_calibrator = calibrator
            
            print(f"ğŸ“Š è®¾ç½®INT8æ ¡å‡†å™¨ï¼Œä½¿ç”¨ {calibration_samples} å¼ æ ¡å‡†å›¾åƒ")
        else:
            print("ğŸ¯ ä½¿ç”¨FP32ç²¾åº¦")
        
        # è§£æONNX
        network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
        parser = trt.OnnxParser(network, self.logger)
        
        print("ğŸ“‚ è§£æONNXæ¨¡å‹...")
        with open(onnx_path, 'rb') as model:
            if not parser.parse(model.read()):
                print("âŒ ONNXè§£æå¤±è´¥:")
                for error in range(parser.num_errors):
                    print(f"   é”™è¯¯ {error}: {parser.get_error(error)}")
                raise RuntimeError("ONNXè§£æå¤±è´¥")
        
        print("âœ… ONNXè§£ææˆåŠŸ")
        
        # è®¾ç½®å±‚çº§ç²¾åº¦çº¦æŸ
        if precision in ['fp16', 'int8']:
            self.set_layer_precision_constraints(network, precision)
        
        # è®¾ç½®åŠ¨æ€å½¢çŠ¶å’Œæ ¡å‡†é…ç½®æ–‡ä»¶
        profile = builder.create_optimization_profile()
        input_name = network.get_input(0).name
        
        # åŠ¨æ€å½¢çŠ¶é…ç½® (min, opt, max)
        min_shape = (1, 3, 256, 320)
        opt_shape = (max_batch_size // 2, 3, 256, 320)  # ä½¿ç”¨ä¸­ç­‰æ‰¹æ¬¡ä½œä¸ºä¼˜åŒ–ç›®æ ‡
        max_shape = (max_batch_size, 3, 256, 320)
        
        profile.set_shape(input_name, min_shape, opt_shape, max_shape)
        config.add_optimization_profile(profile)
        
        # ä¸ºINT8æ ¡å‡†è®¾ç½®é»˜è®¤é…ç½®æ–‡ä»¶
        if precision == 'int8':
            print("ğŸ”§ ä¸ºINT8æ ¡å‡†è®¾ç½®ä¼˜åŒ–é…ç½®æ–‡ä»¶...")
            config.set_calibration_profile(profile)
        
        # è®¾ç½®ç®—æ³•é€‰æ‹©å™¨è¶…æ—¶ï¼ˆå¢åŠ æ„å»ºæ—¶é—´ä½†å¯èƒ½è·å¾—æ›´å¥½æ€§èƒ½ï¼‰
        config.algorithm_selector = None  # ä½¿ç”¨é»˜è®¤ç®—æ³•é€‰æ‹©å™¨
        print("ğŸ”§ ä½¿ç”¨é»˜è®¤ç®—æ³•é€‰æ‹©å™¨è¿›è¡Œæœ€ä¼˜åŒ–")
        
        # æ„å»ºå¼•æ“
        print("ğŸ—ï¸  æ„å»ºTensorRTå¼•æ“...")
        if precision == 'int8':
            print("â³ INT8é‡åŒ–éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
        
        start_time = time.time()
        
        serialized_engine = builder.build_serialized_network(network, config)
        if serialized_engine is None:
            raise RuntimeError("TensorRTå¼•æ“æ„å»ºå¤±è´¥")
        
        build_time = time.time() - start_time
        print(f"âœ… å¼•æ“æ„å»ºå®Œæˆï¼Œè€—æ—¶: {build_time:.2f}ç§’")
        
        # ä¿å­˜å¼•æ“
        print("ğŸ’¾ ä¿å­˜TensorRTå¼•æ“...")
        with open(output_path, 'wb') as f:
            f.write(serialized_engine)
        
        # è·å–æ–‡ä»¶å¤§å°
        engine_size = os.path.getsize(output_path) / (1024 * 1024)
        print(f"âœ… TensorRTå¼•æ“ä¿å­˜æˆåŠŸ: {output_path}")
        print(f"ğŸ“ å¼•æ“å¤§å°: {engine_size:.2f} MB")
        
        return output_path
    
    def validate_engine_precision(self, engine_path, test_image_path=None):
        """éªŒè¯TensorRTå¼•æ“çš„ç²¾åº¦"""
        if not test_image_path or not os.path.exists(test_image_path):
            print("âš ï¸  æœªæä¾›æµ‹è¯•å›¾åƒï¼Œè·³è¿‡ç²¾åº¦éªŒè¯")
            return
        
        try:
            import pycuda.driver as cuda
            
            # åŠ è½½å¼•æ“
            with open(engine_path, 'rb') as f:
                engine_data = f.read()
            
            runtime = trt.Runtime(self.logger)
            engine = runtime.deserialize_cuda_engine(engine_data)
            
            if engine is None:
                print("âŒ å¼•æ“åŠ è½½å¤±è´¥")
                return
            
            # åˆ›å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
            context = engine.create_execution_context()
            
            # è·å–è¾“å…¥è¾“å‡ºä¿¡æ¯
            input_shape = engine.get_binding_shape(0)
            output_shape = engine.get_binding_shape(1)
            
            print(f"ğŸ“Š å¼•æ“éªŒè¯ä¿¡æ¯:")
            print(f"   è¾“å…¥å½¢çŠ¶: {input_shape}")
            print(f"   è¾“å‡ºå½¢çŠ¶: {output_shape}")
            print(f"   æœ€å¤§æ‰¹æ¬¡å¤§å°: {engine.max_batch_size}")
            print(f"   è®¾å¤‡å†…å­˜ä½¿ç”¨: {engine.device_memory_size / 1024 / 1024:.2f} MB")
            
            # ç®€å•çš„æ¨ç†æµ‹è¯•
            print("ğŸ§ª æ‰§è¡Œç®€å•æ¨ç†æµ‹è¯•...")
            
            # å‡†å¤‡æµ‹è¯•æ•°æ®
            test_image = cv2.imread(test_image_path)
            if test_image is not None:
                test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)
                test_image = cv2.resize(test_image, (320, 256), interpolation=cv2.INTER_LINEAR)
                test_image = test_image.astype(np.float32) / 255.0
                test_image = np.transpose(test_image, (2, 0, 1))
                test_input = np.expand_dims(test_image, axis=0)
                
                # åˆ†é…GPUå†…å­˜
                input_mem = cuda.mem_alloc(test_input.nbytes)
                output_mem = cuda.mem_alloc(np.prod(output_shape) * np.dtype(np.float32).itemsize)
                
                # å¤åˆ¶è¾“å…¥æ•°æ®åˆ°GPU
                cuda.memcpy_htod(input_mem, test_input)
                
                # æ‰§è¡Œæ¨ç†
                context.execute_v2([int(input_mem), int(output_mem)])
                
                print("âœ… æ¨ç†æµ‹è¯•æˆåŠŸ")
                
                # æ¸…ç†å†…å­˜
                input_mem.free()
                output_mem.free()
            
        except Exception as e:
            print(f"âš ï¸  ç²¾åº¦éªŒè¯å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•° - ä¼˜åŒ–ç‰ˆONNXåˆ°TensorRTè½¬æ¢å·¥å…·"""
    parser = argparse.ArgumentParser(description='ONNXåˆ°TensorRTè½¬æ¢å·¥å…·ï¼ˆä¼˜åŒ–ç‰ˆï¼Œæ”¯æŒINT8é‡åŒ–å’Œç²¾åº¦éªŒè¯ï¼‰')
    
    # å¿…éœ€å‚æ•°
    parser.add_argument('--onnx', type=str, default='./models/onnx/ultralight_segmentation_256x320.onnx', help='è¾“å…¥ONNXæ¨¡å‹è·¯å¾„')
    
    # å¯é€‰å‚æ•°
    parser.add_argument('--output', type=str, default='./models/trt/ultralight_segmentation_256x320_fp16_optimized.trt', help='è¾“å‡ºTensorRTå¼•æ“è·¯å¾„')
    parser.add_argument('--precision', type=str, default='fp16', 
                       choices=['fp32', 'fp16', 'int8'], help='ç²¾åº¦æ¨¡å¼')
    parser.add_argument('--max-batch-size', type=int, default=4, help='æœ€å¤§æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--workspace-size', type=int, default=4, help='å·¥ä½œç©ºé—´å¤§å° GBï¼ˆå¢åŠ ä»¥è·å¾—æ›´å¥½ä¼˜åŒ–ï¼‰')
    parser.add_argument('--calibration-dir', type=str, default='./test/all_test/images', 
                       help='INT8æ ¡å‡†æ•°æ®ç›®å½•ï¼ˆINT8æ¨¡å¼å¿…éœ€ï¼‰')
    parser.add_argument('--calibration-samples', type=int, default=100,
                       help='æ ¡å‡†æ ·æœ¬æ•°é‡ï¼ˆé»˜è®¤100å¼ ï¼Œæ›´å¤šæ ·æœ¬é€šå¸¸è·å¾—æ›´å¥½ç²¾åº¦ï¼‰')
    
    # ä¼˜åŒ–é€‰é¡¹
    parser.add_argument('--disable-strict-types', action='store_true', help='ç¦ç”¨ä¸¥æ ¼ç±»å‹æ£€æŸ¥')
    parser.add_argument('--disable-tactic-sources', action='store_true', help='ç¦ç”¨ç­–ç•¥æºä¼˜åŒ–')
    parser.add_argument('--test-image', type=str, help='ç”¨äºç²¾åº¦éªŒè¯çš„æµ‹è¯•å›¾åƒè·¯å¾„')
    
    # è°ƒè¯•é€‰é¡¹
    parser.add_argument('--verbose', action='store_true', help='è¯¦ç»†è¾“å‡º')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥INT8å‚æ•°
    if args.precision == 'int8' and args.calibration_dir is None:
        print("âŒ INT8é‡åŒ–éœ€è¦æä¾›æ ¡å‡†æ•°æ®ç›®å½•")
        print("è¯·ä½¿ç”¨: --calibration-dir /path/to/calibration/images")
        return 1
    
    # åˆ›å»ºè½¬æ¢å™¨
    logger_level = trt.Logger.VERBOSE if args.verbose else trt.Logger.WARNING
    converter = ONNXToTensorRTConverter(logger_level)
    
    try:
        # æ‰§è¡Œè½¬æ¢
        engine_path = converter.convert(
            onnx_path=args.onnx,
            output_path=args.output,
            precision=args.precision,
            max_batch_size=args.max_batch_size,
            workspace_size=args.workspace_size,
            calibration_dir=args.calibration_dir,
            calibration_samples=args.calibration_samples,
            enable_strict_types=not args.disable_strict_types,
            enable_tactic_sources=not args.disable_tactic_sources
        )
        
        print(f"\nğŸ‰ è½¬æ¢å®Œæˆ!")
        print(f"TensorRTå¼•æ“: {engine_path}")
        
        # æ˜¾ç¤ºä¼˜åŒ–ä¿¡æ¯
        print(f"\nğŸ“ˆ ä¼˜åŒ–é…ç½®:")
        print(f"   ç²¾åº¦æ¨¡å¼: {args.precision}")
        print(f"   æœ€å¤§æ‰¹æ¬¡: {args.max_batch_size}")
        print(f"   å·¥ä½œç©ºé—´: {args.workspace_size} GB")
        print(f"   ä¸¥æ ¼ç±»å‹æ£€æŸ¥: {'å¯ç”¨' if not args.disable_strict_types else 'ç¦ç”¨'}")
        print(f"   ç­–ç•¥æºä¼˜åŒ–: {'å¯ç”¨' if not args.disable_tactic_sources else 'ç¦ç”¨'}")
        
        if args.precision == 'int8':
            print(f"\nğŸ“Š INT8é‡åŒ–å®Œæˆï¼Œæ¨¡å‹å¤§å°åº”æ˜¾è‘—å‡å°")
            print(f"   æ ¡å‡†æ ·æœ¬æ•°é‡: {args.calibration_samples}")
            cache_file = engine_path.replace('.trt', '_calibration.cache')
            if os.path.exists(cache_file):
                print(f"   ğŸ’¾ æ ¡å‡†ç¼“å­˜å·²ä¿å­˜: {cache_file}")
        
        # æ‰§è¡Œç²¾åº¦éªŒè¯
        if args.test_image:
            print(f"\nğŸ§ª å¼€å§‹ç²¾åº¦éªŒè¯...")
            converter.validate_engine_precision(engine_path, args.test_image)
        
        # æ€§èƒ½å»ºè®®
        print(f"\nğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
        if args.precision == 'fp32':
            print(f"   - è€ƒè™‘ä½¿ç”¨FP16ç²¾åº¦ä»¥è·å¾—æ›´å¥½æ€§èƒ½")
        elif args.precision == 'fp16':
            print(f"   - å½“å‰ä½¿ç”¨FP16ï¼Œæ€§èƒ½å’Œç²¾åº¦çš„è‰¯å¥½å¹³è¡¡")
            print(f"   - å¦‚éœ€æ›´é«˜æ€§èƒ½ï¼Œå¯å°è¯•INT8é‡åŒ–")
        elif args.precision == 'int8':
            print(f"   - å½“å‰ä½¿ç”¨INT8ï¼Œæœ€é«˜æ€§èƒ½æ¨¡å¼")
            print(f"   - å¦‚ç²¾åº¦ä¸è¶³ï¼Œå¯å¢åŠ æ ¡å‡†æ ·æœ¬æ•°é‡æˆ–ä½¿ç”¨FP16")
        
        print(f"   - æ ¹æ®å®é™…ä½¿ç”¨è°ƒæ•´max_batch_sizeä»¥è·å¾—æœ€ä½³æ€§èƒ½")
        print(f"   - å¢åŠ workspace_sizeå¯èƒ½è·å¾—æ›´å¥½ä¼˜åŒ–ï¼ˆå½“å‰: {args.workspace_size}GBï¼‰")
        
    except Exception as e:
        print(f"\nâŒ è½¬æ¢å¤±è´¥: {e}")
        print(f"\nğŸ”§ æ•…éšœæ’é™¤å»ºè®®:")
        print(f"   - æ£€æŸ¥ONNXæ¨¡å‹æ˜¯å¦æœ‰æ•ˆ")
        print(f"   - ç¡®ä¿æœ‰è¶³å¤Ÿçš„GPUå†…å­˜")
        print(f"   - å°è¯•å‡å°workspace_sizeæˆ–max_batch_size")
        print(f"   - å¯¹äºINT8ï¼Œç¡®ä¿æ ¡å‡†æ•°æ®ç›®å½•å­˜åœ¨ä¸”åŒ…å«å›¾åƒ")
        print(f"   - ä½¿ç”¨--verboseæŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯")
        return 1
    
    return 0

if __name__ == '__main__':

    # è¿è¡Œä¸»ç¨‹åº
    exit(main())

